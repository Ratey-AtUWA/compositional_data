---
documentclass: article
classoption: a4paper
geometry: margin=0.6in
output: 
  pdf_document: 
    fig_caption: TRUE
    number_sections: TRUE
    toc: no
    highlight: tango
  html_document: 
    fig_caption: true
    number_sections: yes
    self_contained: no
  word_document: 
    toc_depth: 2
    fig_caption: yes
fontsize: 12pt
header-includes:
  \usepackage{sourcesanspro}
  \usepackage[T1]{fontenc}
  \renewcommand{\familydefault}{\sfdefault}
  \renewcommand{\thefigure}{3.\arabic{figure}}
  \renewcommand{\thetable}{3.\arabic{table}}
---

\setcounter{section}{2}

```{r load knitr, include=FALSE}
library(flextable)
library(magrittr)
library(png)

set_flextable_defaults(theme_fun = "theme_zebra", 
                       font.size = 9, fonts_ignore = TRUE)
BorderDk <- officer::fp_border(color = "#B5C3DF", style = "solid", width = 1)
BorderLt <- officer::fp_border(color = "#FFFFFF", style = "solid", width = 1)

palette(c("black", "#003087", "#DAAA00", "#8F92C4", "#E5CF7E", 
          "#001D51", "#B7A99F", "#A51890", "#C5003E", "#FDC596", 
          "#AD5D1E", "gray40", "gray85", "#FFFFFF", "transparent"))

addImg <- function(obj, x = NULL, y = NULL, width = NULL, interpolate = TRUE){
  if(is.null(x) | is.null(y) | is.null(width)){stop("Must provide args 'x', 'y', and 'width'")}
  USR <- par()$usr ; PIN <- par()$pin ; DIM <- dim(obj) ; ARp <- DIM[1]/DIM[2]
  WIDi <- width/(USR[2]-USR[1])*PIN[1] ;   HEIi <- WIDi * ARp 
  HEIu <- HEIi/PIN[2]*(USR[4]-USR[3]) 
  rasterImage(image = obj, xleft = x-(width/2), xright = x+(width/2),
            ybottom = y-(HEIu/2), ytop = y+(HEIu/2), interpolate = interpolate)
}
```

```{r page 1 header hide code, fig.height=1.5, fig.width=10, echo=FALSE, out.width="100%", fig.align='right', results='hold'}
logo <- readPNG("UWA logo_text_V_wsL.png")
par(mar = c(0,0,0,0))
layout(matrix(c(1,1,1,1,2),nrow = 1))

plot(c(0,1),c(0,1), axes=F, type="n",xaxt="n", yaxt="n",ann=F)
text(-0.025,0.9, pos = 4, cex = 2.6, font = 2, 
     labels="ENVTM501 Data Analysis in R for Compositional Data")
text(-0.025,0.6, pos = 4, cex = 2.2, 
     labels="Multivariate analyses on cities land-use compositional data")
text(-0.025,0.4, pos = 4, font = 3, cex = 1.4, col = 12,
     labels="Land use proportional area data for 40 cities on Earth")
text(1,0.1, pos = 2, font = 3, family = 'serif', cex = 1.5, col = 2,
     labels="Andrew Rate, School of Agriculture and Environment")
plot(1,1, axes=F, type="n",xaxt="n", yaxt="n",ann=F)
addImg(logo, x = 1.2, y = 1, width = 0.5)
par(mar = c(3.5,3.5,0.5,0.5))
```

```{r load packages etc., message=FALSE, warning=FALSE, include=FALSE, results='hide'}
library(rgr)
library(car)
library(cluster)
library(factoextra)
library(ggplot2)
library(reshape2)
library(ggpubr)
library(flextable)
library(magrittr)

set_flextable_defaults(theme_fun = "theme_zebra", 
                       font.size = 9, fonts_ignore = TRUE)
BorderDk <- officer::fp_border(color = "#B5C3DF", style = "solid", width = 1)
BorderLt <- officer::fp_border(color = "#FFFFFF", style = "solid", width = 1)

palette(c("black","blue","green4","red2","purple","darkcyan",
          "firebrick","grey","grey40","white","transparent"))
```

```{r read file and show data, include=FALSE, results='hide'}
cities <- read.csv("cities_Hu_etal_2021.csv", stringsAsFactors = TRUE)
cities$City <- as.character(cities$City)
```

```{r make new Type factor with abbreviated names, include=FALSE, results='hide'}
row.names(cities) <- as.character(cities$City)
cities$sType <- as.character(cities$Type)
cities$sType <- gsub("Compact-Open","CO",cities$sType)
cities$sType <- gsub("Open-Lightweight","OL",cities$sType)
cities$sType <- gsub("Compact","C",cities$sType)
cities$sType <- gsub("Open","O",cities$sType)
cities$sType <- gsub("Industrial","I",cities$sType)
cities$sType <- as.factor(cities$sType)
```

```{r clr-tranform data, include=FALSE, results='hide'}
cities_clr <- cities
cities_clr[,c("Compact","Open","Lightweight","Industry")] <- 
  clr(cities_clr[,c("Compact","Open","Lightweight","Industry")])
names(cities);cat("\n");names(cities_clr)
```

\footnotesize

*We are using the same cities land-use dataset from the previous
session, from Hu et al. (2021).*

\normalsize

# Hierarchical clustering

Hierarchical clustering is another *unsupervised* classification method,
which groups observations into successively larger clusters (i.e.
hierarchically) depending on their *multivariate similarity or
dissimilarity*. The procedure first requires generation of a distance
matrix, following which the clustering procedure can begin.

## Create dissimilarity (distance) matrix for closed data

```{r distance matrix closed, message=FALSE, warning=FALSE, results='hold'}
dataHC <- na.omit(cities[,c("City","sType","Compact","Open","Lightweight","Industry")])
row.names(dataHC) <- paste0(dataHC$City,"(",dataHC$sType, seq(1,NROW(dataHC)),")")
dataHC$City <- NULL
dataHC$sType <- NULL
cities_clos_diss <- get_dist(dataHC, method = "euclidean")
cat("First 8 rows and first 4 columns of distance matrix:\n")
round(as.matrix(cities_clos_diss)[1:8, 1:4], 0)
```

\normalsize

## Create dissimilarity (distance) matrix for open data

\scriptsize

```{r distance matrix open, message=FALSE, warning=FALSE, results='hold'}
dataHC <- na.omit(cities_clr[,c("City","sType","Compact","Open","Lightweight","Industry")])
row.names(dataHC) <- paste0(dataHC$City,"(",dataHC$sType, seq(1,NROW(dataHC)),")")
dataHC$City <- NULL
dataHC$sType <- NULL
cities_open_diss <- get_dist(dataHC, method = "euclidean")
cat("First 8 rows and first 4 columns of distance matrix:\n")
round(as.matrix(cities_open_diss)[1:8, 1:4], 2)
```

\normalsize

The distance matrix, part of which (the 'top-left' corner) is shown
here, shows the distance in terms of the measurement variables between
any pair of points. In this case the variables are
"Compact","Open","Lightweight",and "Industry", so the resulting
4-dimensional space is hard to visualise, but for *Euclidean distance*
used here it represents the equivalent of straight-line distance between
each observation, each defined by a 4-dimensional vector. There are
several other ways to define distance (or *(dis)similarity*) which are
used in various disciplines, such as Manhattan, Jaccard, Bray-Curtis,
Mahalonobis (and others based on covariance/correlation), or Canberra.
[Try running **?factoextra::dist** and read the information for 'method'
for additional information.]

## Perform hierarchical clustering for closed data

The hierarchical clustering algorithm **(1)** assigns each observation
to its own cluster, each containing only one observation. So, at the
beginning, the distances (or (dis)similarities) between the clusters is
the same as the distances between the items they contain. **(2)** The
closest pair of clusters is then computed, and this pair is merged into
a single cluster. **(3)** Distances are re-calculated between the new
cluster and each of the old clusters, and steps 2 and 3 are repeated
until all items are clustered into a single cluster. Finally, now the
algorithm has generated a complete hierarchical tree, we can split the
observations into *k* clusters by separating them at the *k*-1 longest
branches (for our closed data, see \autoref{hclustClos}).

Since the clusters are a group of points rather than single points,
there are several ways of combining the observations into clusters --
run **?stats::hclust** and see under 'method' for more information.

\scriptsize

```{r hierarchical clustering closed, fig.height=12, fig.width=10, message=FALSE, warning=FALSE, fig.align='center', fig.cap="\\label{hclustComp}Hierarchical cluster dendrogram for (a) compositionally closed and (b) open (CLR-transformed) urban land-use data.", results='hold'}
cities_clos_hc <- hclust(cities_clos_diss, method = "ward.D2")
cities_open_hc <- hclust(cities_open_diss, method = "ward.D2")
par(mfrow=c(2,1), mgp = c(1.7,0.3,0), tcl = 0.25)
plot(cities_clos_hc, cex=0.8, main=""); mtext("(a)", adj = 0.05)
abline(h = c(870,1050,1500), col = c("blue2","purple","red3"), lty = c(2,5,1))
# text(3,870, pos=3, labels="Cut for 5 clusters", col = "blue2", offset = 0.2)
text(c(3,3,3),c(870,1050,1500), pos=3, col = c("blue2","purple","red3"), offset = 0.2, 
     labels=c("Cut for 5 clusters","Cut for 4 clusters","Cut for 3 clusters"))
plot(cities_open_hc, cex=0.8, main=""); mtext("(b)", adj = 0.05)
abline(h = c(3.7,8,10), col = c("blue2","purple","red3"), lty = c(2,5,1))
# text(3,870, pos=3, labels="Cut for 5 clusters", col = "blue2", offset = 0.2)
text(c(38,38,38),c(3.7,8,10), pos=3, col = c("blue2","purple","red3"), offset = 0.2, 
     labels=c("Cut for 5 clusters","Cut for 4 clusters","Cut for 3 clusters"))
```

\normalsize

The plots in \autoref{hclustComp} are hierarchical clustering 'trees',
or *dendrograms*. We can see that the lowest order clusters, joined
above the variable names, contain two observations (cities, in this
dataset), reflecting the first iteration of Step 2 in the clustering
algorithm described above. As we look higher in the dendrogram, we see
additional observations or clusters grouped together, until at the
highest level a single grouping exists. 'Cutting' the dendrogram at
different heights will result in different numbers of clusters; the
lower the cut level, the more clusters we will have. For both the closed
and open data we have shown cuts in \autoref{hclustComp} resulting in 3,
4, or 5 clusters. There are numerous ways to decide where to make the
cut; see Kassambara (2018) (<https://shorturl.at/cntxH> ) for some of
these.

## Assess the validity of cluster trees

**For closed data:**

\scriptsize

```{r verify cluster tree closed, results='hold'}
cities_clos_coph <- cophenetic(cities_clos_hc)
cat("Correlation coefficient r =",cor(cities_clos_diss,cities_clos_coph),"\n")
cat("\nRule-of-thumb:\n",
 "Cluster tree represents actual distance matrix accurately enough if r>0.75\n")
```

\normalsize

**For open data:**

\scriptsize

```{r verify cluster tree open, results='hold'}
cities_open_coph <- cophenetic(cities_open_hc)
cat("Correlation coefficient r =",cor(cities_open_diss,cities_open_coph),"\n")
```

\normalsize

The *cophenetic distance* may be considered a 'back calculation' of the
distance matrix based on the dendrogram (run **?cophenetic** for more
details). We then calculate a correlation coefficient between the actual
distance matrix and the cophenetic distance matrix. If the correlation
is great enough (nominally \> 0.75), we assume that the dendrogram
adequately represents our data. (If the actual *vs*. cophenetic
correlation is too low, we may want to choose another distance measure,
or a different hierarchical clustering algorithm.) Our results show that
the dendrograms for both closed and open data are adequate
representations of the applicable distance matrices.

## Find the optimum number of clusters

We did a similar analysis on the same datasets (closed and open cities
land-use) for K-means clustering, estimating the optimum number of
clusters using the 'weighted sum-of-squares' (wss) method. In
\autoref{nClustComp} we estimate the best cluster numbers using another
common method, the *silhouette* method.

\scriptsize

```{r assess optimum clusters for closed and open data, fig.height=3, fig.width=7.2, out.width='75%', fig.align='center', fig.cap="\\label{nClustComp}Estmation of the optimum number of clusters by the silhouette method for (a) compositionally closed and (b) open (CLR-transformed) urban land-use data.", results='hold'}
#
require(factoextra)
data0 <- na.omit(cities[,c("Compact","Open","Lightweight","Industry")])
nclus_clos <- fviz_nbclust(data0, kmeans, method = "silhouette", verbose = F) +
  labs(title="")
data0 <- na.omit(cities_clr[,c("Compact","Open","Lightweight","Industry")])
nclus_clr <- fviz_nbclust(data0, kmeans, method = "silhouette", verbose = F) +
  labs(title="")
ggarrange(nclus_clos,nclus_clr,ncol = 2,nrow = 1, 
          labels = c("(a) closed","(b) open (clr)"))
```

\normalsize

## Cut dendrograms into clusters

This was illustrated in \autoref{hclustComp} above, and we now
investigate the clustering in more detail, assuming 4 clusters for both
closed and open data.

**Clusters for closed data**

\scriptsize

```{r cut dendrogram closed, paged.print=FALSE, tab.cap="Cities in each hierarchical cluster from analysis of compsitionally closed data.", results='hold'}
cities_clos_grp <- cutree(cities_clos_hc, k = 4)
outtable <- data.frame(Cluster = seq(1,nlevels(as.factor(cities_clos_grp))),
                       Cities = rep("nil",nlevels(as.factor(cities_clos_grp))),
                       Freq = rep(0,nlevels(as.factor((cities_clos_grp)))))
tccg <- data.frame(table(cities_clos_grp))
for (i in 1:nlevels(as.factor(cities_clos_grp))) {
  outtable[i,1] <- paste("Cluster",i)
  outtable[i,2] <- paste(names(which(cities_clos_grp==i)), 
                         collapse = " ")
  outtable[i,3] <- as.numeric(tccg[i,2])}
ft <- flextable(outtable)
ft <- theme_zebra(ft,odd_header = "#D0E0FF")
ft <- border_outer(ft, border=BorderDk, part = "all")
ft <- border_inner_v(ft, border=BorderLt, part="all")
ft %>% width(j=1:3, width=c(1,5,1), unit = "in")
```

```{r cut dendrogram open, paged.print=FALSE, tab.cap="Cities in each hierarchical cluster from analysis of open (CLR-transformed) data.", results='hold'}
cities_open_grp <- cutree(cities_open_hc, k = 4)
tccg <- data.frame(table(cities_open_grp))
outtable <- data.frame(Cluster = seq(1,nlevels(as.factor(cities_open_grp))),
                       Cities = rep("nil",nlevels(as.factor(cities_open_grp))),
                       Freq = rep(0,nlevels(as.factor((cities_open_grp)))))
for (i in 1:nlevels(as.factor(cities_open_grp))) {
  outtable[i,1] <- paste("Cluster",i)
  outtable[i,2] <- paste(names(which(cities_open_grp==i)), 
                         collapse = " ")
  outtable[i,3] <- as.numeric(tccg[i,2])}
ft <- flextable(outtable)
ft <- theme_zebra(ft,odd_header = "#D0E0FF")
ft <- border_outer(ft, border=BorderDk, part = "all")
ft <- border_inner_v(ft, border=BorderLt, part="all")
ft %>% width(j=1:3, width=c(1,5,1), unit = "in")
```

\normalsize

The decision to cut the dendrograms into 4 clusters (*i.e*. at a level
which intersects exactly 4 'branches') is somewhat subjective, but could
be based on other information such as K-means clustering, PCA, or
pre-existing knowledge of the data.

A diagram comparing the clusters in cut dendrograms for closed and open
data is shown below, in \autoref{hclustCutComp}.

## Plot dendrograms comparing closed and open data with cuts

\scriptsize

```{r plot cut dendrogram open, fig.height=10, fig.width=10, message=FALSE, warning=FALSE, fig.align='center', fig.cap="\\label{hclustCutComp}Hierarchical cluster dendrograms for (a) closed and (b) CLR-transformed (open) urban land-use data, showing clusters within dashed rectangles.", results='hold'}
gg_cutden_clos <- fviz_dend(cities_clos_hc, k = 4, # Cut in five groups
          main = "", cex = 0.7, # label size
          k_colors = c("gray40","red3", "blue2", "purple"),
          color_labels_by_k = TRUE, # color labels by groups
          rect = TRUE, # Add rectangle around groups
          labels_track_height = 1320 # adjust low margin for long labels
)
gg_cutden_open <- fviz_dend(cities_open_hc, k = 4, # Cut in five groups
          main = "", cex = 0.7, # label size
          k_colors = c("gray40","red3", "blue2", "purple"),
          color_labels_by_k = TRUE, # color labels by groups
          rect = TRUE, # Add rectangle around groups
          labels_track_height = 10 # adjust low margin for long labels
)
ggarrange(gg_cutden_clos,gg_cutden_open, nrow = 2, 
          labels = c("(a) closed","(b) open (CLR)"))
```

\normalsize

This session has shown us how to apply the unsupervised classification
method, **hierarchical clustering** to a dataset and observe the effects
of removing compositional closure. Different clustering, and potentially
even different numbers of clusters, result from the closed and open
(CLR-transformed) versions of our cities land-use data.

## References and R Packages

Hu, J., Wang, Y., TaubenbÃ¶ck, H., Zhu, X.X. (2021). Land consumption in
cities: A comparative study across the globe. *Cities*, **113**: 103163,
<https://doi.org/10.1016/j.cities.2021.103163>.

Kassambara, A. (2018). *Determining The Optimal Number Of Clusters: 3
Must* *Know Methods*. Datanovia, Montpellier, France.
(<https://shorturl.at/cntxH>)

Kassambara, A. and Mundt, F. (2020). *factoextra: Extract and Visualize
the* *Results of Multivariate Data Analyses*. R package version 1.0.7.
<https://CRAN.R-project.org/package=factoextra>

Maechler, M., Rousseeuw, P., Struyf, A., Hubert, M., Hornik, K.(2021).
*cluster: Cluster Analysis Basics and Extensions*. R package version
2.1.2. <https://CRAN.R-project.org/package=cluster>

Reimann, C., Filzmoser, P., Garrett, R. G., & Dutter, R. (2008).
*Statistical Data Analysis Explained: Applied Environmental Statistics
with R* (First ed.). John Wiley & Sons, Chichester, UK.

Venables, W. N. & Ripley, B. D. (2002) *Modern Applied Statistics with
S* (**MASS**). Fourth Edition. Springer, New York. ISBN 0-387-95457-0.
<http://www.stats.ox.ac.uk/pub/MASS4/>

Wickham, H. (2019). *stringr: Simple, Consistent Wrappers for Common
String* *Operations*. R package version 1.4.0.
<https://CRAN.R-project.org/package=stringr>
