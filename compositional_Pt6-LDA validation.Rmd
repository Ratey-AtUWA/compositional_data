---
documentclass: article
classoption: a4paper
geometry: margin=0.6in
output: 
  pdf_document: 
    fig_caption: TRUE
    number_sections: TRUE
    toc: no
    highlight: tango
  html_document: 
    toc_depth: 2
    fig_caption: yes
    number_sections: yes
    self_contained: no
  word_document: 
    toc_depth: 2
    fig_caption: yes
fontsize: 12pt
header-includes:
  \usepackage{sourcesanspro}
  \usepackage[T1]{fontenc}
  \renewcommand{\familydefault}{\sfdefault}
  \renewcommand{\thefigure}{6.\arabic{figure}}
  \renewcommand{\thetable}{6.\arabic{table}}
---

\setcounter{section}{5}

```{r load knitr, include=FALSE}
library(flextable)
library(magrittr)
library(png)

set_flextable_defaults(theme_fun = "theme_zebra", 
                       font.size = 9, fonts_ignore = TRUE)
BorderDk <- officer::fp_border(color = "#B5C3DF", style = "solid", width = 1)
BorderLt <- officer::fp_border(color = "#FFFFFF", style = "solid", width = 1)

palette(c("black", "#003087", "#DAAA00", "#8F92C4", "#E5CF7E", 
          "#001D51", "#B7A99F", "#A51890", "#C5003E", "#FDC596", 
          "#AD5D1E", "gray40", "gray85", "#FFFFFF", "transparent"))

addImg <- function(obj, x = NULL, y = NULL, width = NULL, interpolate = TRUE){
  if(is.null(x) | is.null(y) | is.null(width)){stop("Must provide args 'x', 'y', and 'width'")}
  USR <- par()$usr ; PIN <- par()$pin ; DIM <- dim(obj) ; ARp <- DIM[1]/DIM[2]
  WIDi <- width/(USR[2]-USR[1])*PIN[1] ;   HEIi <- WIDi * ARp 
  HEIu <- HEIi/PIN[2]*(USR[4]-USR[3]) 
  rasterImage(image = obj, xleft = x-(width/2), xright = x+(width/2),
            ybottom = y-(HEIu/2), ytop = y+(HEIu/2), interpolate = interpolate)
}
```

```{r page 1 header hide code, fig.height=1.5, fig.width=10, echo=FALSE, out.width="100%", fig.align='right', results='hold'}
logo <- readPNG("UWA logo_text_V_wsL.png")
par(mar = c(0,0,0,0))
layout(matrix(c(1,1,1,1,2),nrow = 1))

plot(c(0,1),c(0,1), axes=F, type="n",xaxt="n", yaxt="n",ann=F)
text(-0.025,0.9, pos = 4, cex = 2.6, font = 2, 
     labels="ENVTM501 Data Analysis in R for Compositional Data")
text(-0.025,0.6, pos = 4, cex = 2.2, 
     labels="Multivariate analyses on whole-rock major element compositional data")
text(-0.025,0.4, pos = 4, font = 3, cex = 1.4, col = 12,
     labels="Geochemical data for the Yilgarn Craton, Western Australia by J.A. Hallberg")
text(1,0.1, pos = 2, font = 3, family = 'serif', cex = 1.5, col = 2,
     labels="Andrew Rate, School of Agriculture and Environment")
plot(1,1, axes=F, type="n",xaxt="n", yaxt="n",ann=F)
addImg(logo, x = 1.2, y = 1, width = 0.5)
par(mar = c(3.5,3.5,0.5,0.5))
```

```{r load packages etc., message=FALSE, warning=FALSE, include=FALSE, results='hide'}
library(rgr)
library(car)
library(cluster)
library(factoextra)
library(ggplot2)
library(reshape2)
library(ggpubr)
library(flextable)
library(magrittr)
library(MASS)
library(RcmdrMisc)

set_flextable_defaults(theme_fun = "theme_zebra", 
                       font.size = 9, fonts_ignore = TRUE)
BorderDk <- officer::fp_border(color = "#B5C3DF", style = "solid", width = 1)
BorderLt <- officer::fp_border(color = "#FFFFFF", style = "solid", width = 1)

UWApal <- c("black", "#003087", "#DAAA00", "#8F92C4", "#E5CF7E", 
          "#001D51", "#B7A99F", "#A51890", "#C5003E", "#FDC596", 
          "#AD5D1E","gray40","gray85","#FFFFFF","transparent"); palette(UWApal)
```

```{r read file and show data, include=FALSE, results='hide'}
Hallberg <- read.csv("Hallberg.csv", stringsAsFactors = TRUE)
```

# Validation of LDA Models for Supervised Classification

We are using a curated version of a whole rock major element dataset
from Hallberg
(<https://catalogue.data.wa.gov.au/dataset/hallberg-geochemistry>)

## Use _ALR_ transformation to remove closure

```{r alr-tranform data, message=FALSE, warning=FALSE, include=TRUE, results='hold'}
Hallberg_alr <- Hallberg
Hallberg_alr[,c(11:12,14:24)] <- 
  alr(Hallberg_alr[,11:24], j = 3, ifwarn = FALSE) # recommend ifwarn = TRUE
```

## LDA on closed whole rock major element data

...using LDA to discriminate the Rock type -- the predictors are the major
element oxide contents.

\scriptsize

```{r LDA closed whole rock data, results='hold'}
data0 <- Hallberg
data0[,c(11:24)] <- scale(data0[,11:24]) # scale just numeric variables
lda_rock_clos <- lda(formula = Rock ~ SiO2 + TiO2 + Fe2O3 + FeO + MnO + 
                       MgO + CaO + Na2O + K2O + P2O5,      # not Al2O3
                    data = data0,
                    prior = as.numeric(summary(Hallberg$Rock))/nrow(Hallberg))
cat("Proportions of between-categories variance explained by each LD\n")
props <- matrix(lda_rock_clos$svd^2/sum(lda_rock_clos$svd^2),nrow = 1)
colnames(props) <- paste0("LD",seq(1:length(props))); print(props, digits=3)
```

\normalsize

## LDA on open (ALR) whole rock major element data

\scriptsize

```{r LDA open ALR whole rock data, message=FALSE, warning=FALSE, results='hold'}
data0 <- Hallberg_alr
data0[,11:24] <- scale(data0[,11:24]) # scale just numeric variables
lda_rock_open <- lda(formula = Rock ~ SiO2 + TiO2 + Fe2O3 + FeO + MnO + 
                       MgO + CaO + Na2O + K2O + P2O5,       # not Al2O3
                    data = data0,
                    prior = as.numeric(summary(data0$Rock))/nrow(data0)) 
cat("Proportions of between-categories variance explained by each LD\n")
props <- matrix(lda_rock_open$svd^2/sum(lda_rock_open$svd^2),nrow = 1)
colnames(props) <- paste0("LD",seq(1:length(props))); print(props, digits=3)
```

\normalsize

We have restricted the normal output of LDA, as we've seen this in previous
sessions. As we've seen in those sessions, for the Hallberg major element
dataset, the first 2 LDA dimensions explain over 95% of the between-categories
variance.

We need to make objects containing the LDA predictions:

```{r make objects for LDA preds, results='hold'}
ldaPred_rock_clos <- predict(lda_rock_clos)
ldaPred_rock_open <- predict(lda_rock_open)
```

## Inspecting the agreement between actual and predicted categories in LDA 

To do this easily we just make an R data frame with columns for the actual
categories (from the original data frame) and the predicted categories (from the
prediction objects we just made). We add a column telling us if these two
columns match in each row (which we can see easily, but we use this column to
calculate a numerical prediction accuracy).

The code below uses the *head()* function to inspect the first few rows of each
comparison, but we could easily look at the whole comparison data frames using
*print()*.

```{r compare models with reality, paged.print=FALSE}
closComp <- data.frame(Actual = as.character(Hallberg$Rock),
                       Predicted = as.character(ldaPred_rock_clos$class))
closComp$test <- as.character(Hallberg_alr$Rock) == 
  as.character(ldaPred_rock_clos$class)
k = length(which(closComp$test == TRUE))
cat("Predictions by LDA using closed data:",k,"out of",NROW(Hallberg_alr),
    "=",paste0(round(100*k/NROW(Hallberg_alr),1),"% correct\n"))
head(closComp, n = 10)

openComp <- data.frame(Actual = as.character(Hallberg_alr$Rock),
                       Predicted = as.character(ldaPred_rock_open$class))
openComp$test <- as.character(Hallberg_alr$Rock) == 
  as.character(ldaPred_rock_open$class)
k = length(which(openComp$test == TRUE))
cat("\nPredictions by LDA using open data:",k,"out of",NROW(Hallberg_alr),
    "=",paste0(round(100*k/NROW(Hallberg_alr),1),"% correct\n"))
head(openComp, n = 10)
```

\normalsize

For this dataset, it seems as though LDA using either closed open open data is
not that good at predicting the Rock category for each observation! In the
output above, Basalt is mis-identified as Dolerite (which might make sense given
the expected compositional similarity; simplistically, dolerite is a more
coarse-grained version of basalt). It seems to be more common for Basalt to be
mis-identified as Metasediment, which may or not make sense depending on the
composition of the original sediment!

This kind of comparison is not very rigorous, and nor does it address the reason
we might perform a supervised classification like LDA -- to use data to predict
*unknown* categories. The ability of LDA to predict unknown categories can be
addressed by validation procedures, such as the one we investigate below.

## Assessment of LDA prediction using a training-validation method

This can be done a different way, by including the **CV = TRUE** option in the
**lda()** function, which implements 'leave one out cross validation'. Simply
stated, this omits one observation at a time, running the LDA on the remaining
data each time, and predicting the probability of the missed observation being
in each category (the *posterior probabilities*). [Each observation is assigned 
to the category with the greatest posterior probability.]

We will use a related method, using 'training' and 'validation' subsets of our
data. The idea here is that we divide the dataset into two (the code below
splits the data in half, but other splits could be used, *e.g*. 0.75:0.25). The
first subset of the data is used to generate an LDA model (*i.e*. a set of linear
discriminant functions), which are then used to try and predict the categories
in the other subset. We choose the observations making up each subset randomly.
Of course, this could give us unreliable results if the random selection happens
to be somehow unbalanced, so we repeat the training-validation process many
times to calculate an average prediction rate.

One glitch that can happen is that in selecting a random subset of the data, the
subset may not include any samples from one or more categories. This problem is
more likely if our data have some categories having relatively few observations.
The code below applies an 'error-catching' condition before running the training
LDA, which is that all categories in a random subset need to be populated.

\scriptsize

```{r LDA train and predict closed, message=FALSE, warning=FALSE, paged.print=FALSE, results='hold'}
n0 <- 100 # number of iterations
ftrain <- 0.5 # proportion of observations in training set
results <- data.frame(
  Rep = rep(NA, n0),
  matches = rep(NA, n0),
  non_matches = rep(NA, n0),
  success = rep(NA, n0))
train <- sample(1:NROW(Hallberg), round(NROW(Hallberg) * ftrain,0))
# make vector of individual category non-matches
matchByClass <- 
  data.frame(Match1 = rep(0,nlevels(Hallberg$Rock[train]))) 
rownames(matchByClass) <- levels(ldaPred_rock_clos$class)
fMatchXClass <- 
  data.frame(PctMch1 = rep(0,nlevels(Hallberg$Rock[train]))) 
rownames(fMatchXClass) <- levels(ldaPred_rock_clos$class)
# make vector of cumulative category counts in Hallberg[-train] iterations
cc0 <- rep(0,nlevels(Hallberg$Rock))
isOK <- 0 ; i <- 2

for (i in 1:n0) {
  train <- sample(1:NROW(Hallberg), round(NROW(Hallberg) * ftrain,0))
      # set condition requiring all categories to be populated
      if (is.na(match(NA,tapply(Hallberg[train,]$SiO2, 
                      Hallberg[train,]$Rock, sd, na.rm=T))) == TRUE) {
          lda_Rock_train <- lda(formula = Rock ~ SiO2 + TiO2 + Fe2O3 + FeO + 
                            MnO + MgO + CaO + Na2O + K2O + P2O5, 
                          data = Hallberg[train,],
                          prior=as.numeric(summary(Hallberg$Rock[train]))/
                            nrow(Hallberg[train,]))
          ldaPred_rock_clos <- predict(lda_Rock_train, Hallberg[-train,])
          isOK <- isOK + 1
        }
  
  k=0               # number of matches
  m0 <-             # vector of individual category matches 
    as.matrix(rep(0,nlevels(Hallberg$Rock[train]))) 
  rownames(m0) <- levels(Hallberg$Rock)
  m1 <-             # vector of fractional category matches 
    as.matrix(rep(0,nlevels(Hallberg$Rock[train]))) 
  rownames(m1) <- levels(Hallberg$Rock)
  for (jM in 1:NROW(Hallberg[-train,])) {
    for (jS in 1:nlevels(ldaPred_rock_clos$class)) {
      if((ldaPred_rock_clos$class[jM] == levels(ldaPred_rock_clos$class)[jS]) & 
         (Hallberg$Rock[-train][jM] == levels(ldaPred_rock_clos$class)[jS]) ) 
        m0[jS] = m0[jS] + 1
      else  m0[jS] = m0[jS] 
    }
    k = sum(m0)
  }
  cc0 <- cc0 + as.numeric(summary(Hallberg$Rock[-train]))
  m1 <- round(100*m0/as.numeric(summary(Hallberg$Rock[-train])),1)
  matchByClass[,paste0("Match",i)] <- m0
  fMatchXClass[,paste0("PctMch",i)] <- m1
  # output to results data frame: iteration, matches, non-matches, proportion matched
  results[i,] <- c(i, k, NROW(Hallberg[-train,])-k, 
                   signif(k/NROW(Hallberg[-train,]),3))
}
# Output code block
cat(paste("[Based on", n0, "random subsets of",paste0(100*ftrain,"%"),
          "of the dataset to train LDA model\n",
     "      to predict remaining observations]\n"))
  cat("Number of obs. in random subsets =",NROW(train),
      " (predicting",NROW(Hallberg)-NROW(train),"samples)\n")
  print(numSummary(results[,2:4], statistics=c("mean","sd"))$table)
  ns0 <- numSummary(results$success)
  t0 <- t.test(results$success)
  cat(rep("-\u2013-",24),
      "\nStat. summary for 'success':\nMean = ",round(ns0$table[1],4),
      ", sd = ",round(ns0$table[2],4),
      ", 95% confidence interval = (",
      signif(t0$conf.int[1],3),", ",signif(t0$conf.int[2],4),
      ") (after ",i," reps)\n", sep="")
  cat(n0-isOK,"iterations 'failed' due to randomisation missing a category\n\n")
  cat("Fraction of matches by category over ALL iterations:\n")
  summCats <- data.frame(
    Rock_Type = row.names(matchByClass),
    Total_Matched = rowSums(matchByClass),
    Actual = cc0,
    Percent_Matched = paste0(round(100*(rowSums(matchByClass)/cc0),1),"%"),
    row.names = NULL)
  print(summCats)
# tidy up
rm(list = c("n0","ftrain","i","isOK","jS","jM","k","m0","m1","t0","cc0",
            "matchByClass","fMatchXClass","results","train","summCats"))
```

\normalsize

The number of iterations makes some difference (\autoref{AccuIter})!

So, it looks like we should run at least 50-100 iterations to get a reasonable 
idea of how well our LDA model performs. More iterations is better, but it 
depends how long you want the run-time to be!

\scriptsize

```{r accuracy vs iterations, fig.height=3.5, fig.width=5, fig.align='center', message=FALSE, warning=FALSE,out.width="40%", fig.cap="\\label{AccuIter}Accuracy (shown by 95 percent CI error bars) as a function of nuber of train-validate iterations for an LDA model using closed whole-rock composition data.", results='hold'}
par(mar = c(3,3,1,1), mgp = c(1.5,0.2,0), tcl = 0.25, font.lab = 2)
plot(c(10,20,50,100,200,500,1000),c(0.5572,0.5986,0.5848,0.5847,0.5837,0.581,0.582), 
     pch=19, cex = 1.2, log = "x", xlim = c(7,1400), ylim = c(0.45,0.65),
     xlab = "Number of iterations", ylab = "Mean accuracy \u00B1 95% CI")
arrows(c(10,20,50,100,200,500,1000),c(0.49,0.58,0.572,0.574,0.577,0.576,0.579),
       c(10,20,50,100,200,500,1000),c(0.624,0.617,0.598,0.595,0.591,0.586,0.585),
       angle = 90, length = 0.1, code = 3)
```

\normalsize

We can run a similar validation process for the ALR-transformed data (we don't
show the code, as it's effectively identical to the code for validation of LDA
for closed data, but with references to 'Hallberg' replaced with
'Hallberg_alr').

\scriptsize

```{r LDA train and predict open, message=FALSE, warning=FALSE, echo=FALSE, paged.print=FALSE, results='hold'}
n0 <- 100 # number of iterations
ftrain <- 0.5 # proportion of observations in training set
results <- data.frame(
  Rep = rep(NA, n0),
  matches = rep(NA, n0),
  non_matches = rep(NA, n0),
  success = rep(NA, n0))
train <- sample(1:NROW(Hallberg_alr), round(NROW(Hallberg_alr) * ftrain,0))
# make vector of individual category non-matches
matchByClass <- 
  data.frame(Match1 = rep(0,nlevels(Hallberg_alr$Rock[train]))) 
rownames(matchByClass) <- levels(ldaPred_rock_open$class)
fMatchXClass <- 
  data.frame(PctMch1 = rep(0,nlevels(Hallberg_alr$Rock[train]))) 
rownames(fMatchXClass) <- levels(ldaPred_rock_open$class)
# make vector of cumulative category counts in Hallberg_alr[-train] iterations
cc0 <- rep(0,nlevels(Hallberg_alr$Rock)) 
isOK <- 0 ; i <- 2

for (i in 1:n0) {
  # train <- sample(1:NROW(Hallberg_alr), round(NROW(Hallberg_alr)-5,0))
  train <- sample(1:NROW(Hallberg_alr), round(NROW(Hallberg_alr) * ftrain,0))
      if (is.na(match(NA,tapply(Hallberg_alr[train,]$SiO2, 
                      Hallberg_alr[train,]$Rock, sd, na.rm=T))) == TRUE) {
          lda_Rock_train <- lda(formula = Rock ~ SiO2 + TiO2 + Fe2O3 + FeO + 
                            MnO + MgO + CaO + Na2O + K2O + P2O5, 
                          data = Hallberg_alr[train,],
                          prior=as.numeric(summary(Hallberg_alr$Rock[train]))/
                            nrow(Hallberg_alr[train,]))
          ldaPred_rock_open <- predict(lda_Rock_train, Hallberg_alr[-train,])
          isOK <- isOK + 1
        }
  
  k=0 # number of matches
  m0 <- # vector of individual category matches 
    as.matrix(rep(0,nlevels(Hallberg_alr$Rock[train]))) 
  rownames(m0) <- levels(Hallberg_alr$Rock)
  m1 <- # vector of fractional category matches 
    as.matrix(rep(0,nlevels(Hallberg_alr$Rock[train]))) 
  rownames(m1) <- levels(Hallberg_alr$Rock)
  for (jM in 1:NROW(Hallberg_alr[-train,])) {
    for (jS in 1:nlevels(ldaPred_rock_open$class)) {
      if((ldaPred_rock_open$class[jM] == levels(ldaPred_rock_open$class)[jS]) & 
         (Hallberg_alr$Rock[-train][jM] == levels(ldaPred_rock_open$class)[jS]) ) 
        m0[jS] = m0[jS] + 1
      else  m0[jS] = m0[jS] 
    }
    k = sum(m0)
  }
  cc0 <- cc0 + as.numeric(summary(Hallberg_alr$Rock[-train]))
  m1 <- round(100*m0/as.numeric(summary(Hallberg_alr$Rock[-train])),1)
  matchByClass[,paste0("Match",i)] <- m0
  fMatchXClass[,paste0("PctMch",i)] <- m1
# output to results data frame: iteration, matches, non-matches, proportion matched
  results[i,] <- c(i, k, NROW(Hallberg_alr[-train,])-k, 
                   signif(k/NROW(Hallberg_alr[-train,]),3))
}

cat(paste("[Based on", n0, "random subsets of",paste0(100*ftrain,"%"),
          "of the dataset to train LDA model\n",
     "      to predict remaining observations]\n"))
  cat("Number of obs. in random subsets =",NROW(train),
      " (predicting",NROW(Hallberg_alr)-NROW(train),"samples)\n")
  print(numSummary(results[,2:4], statistics=c("mean","sd"))$table)
  ns0 <- numSummary(results$success)
  t0 <- t.test(results$success)
  cat(rep("-\u2013-",24),
      "\nStat. summary for 'success':\nMean = ",round(ns0$table[1],4),
      ", sd = ",round(ns0$table[2],4),
      ", 95% confidence interval = (",
      signif(t0$conf.int[1],3),", ",signif(t0$conf.int[2],4),
      ") (after ",i," reps)\n", sep="")
  cat(n0-isOK,"iterations 'failed' due to randomisation missing a category\n\n")
  cat("Fraction of matches by category over ALL iterations:\n")
  summCats <- data.frame(
    Rock_Type = row.names(matchByClass),
    Total_Matched = rowSums(matchByClass),
    Actual = cc0,
    Percent_Matched = paste0(round(100*(rowSums(matchByClass)/cc0),1),"%"),
    row.names = NULL)
  print(summCats)
rm(list = c("n0","ftrain","i","isOK","jS","jM","k","m0","m1","t0","cc0",
            "matchByClass","fMatchXClass","results","train","summCats"))
```

\normalsize

If we compare the validation output for the open data with the results for
closed data, we see very little difference in overall accuracy. Both closed and
open data generated successful predictions 62.7% of the time, with a slightly
lower standard deviation for LDA based on open data. 

There were small differences (in this validation exercise), between closed and
open data, in the ability of LDA to predict specific categories. Closed-data LDA
seemed better at predicting Dolerite, Gabbro, High Mg Basalt, and Metasediment.
Conversely, LDA using open data seemed better at predicting Basalt, Peridotite,
Pyroxenite, and Spinel Peridotite.

We may get better prediction accuracy by including different variables in the
LDA model. The original Hallberg geochemistry data at
https://catalogue.data.wa.gov.au/dataset/hallberg-geochemistry also contain
trace element concentrations, which can sometimes provide better discrimination
than major element concentrations alone. This would be an interesting exercise to extend one's skills in data curation and multivariate analysis of compositional data.

An issue that we haven't considered yet is whether all the variables we used for
prediction are necessary. The R package '**klaR**' (Weihs et al. 2005) includes
the *stepclass()* function, which enables us to refine an LDA model, using a
procedure similar to stepwise selection of predictors in multiple regression.

```{r remove temp LDA objects, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
rm(list = c("n0","ftrain","i","e0","jS","jM","k","m0",
            "matchByClass","results","train"))
```

### References

Campbell, G. P., Curran, J. M., Miskelly, G. M., Coulson, S., Yaxley, G.
M., Grunsky, E. C., & Simon C. Cox. (2009). Compositional data analysis
for elemental data in forensic science. *Forensic Science
International*, **188**, 81-90.
<https://doi.org/10.1016/j.forsciint.2009.03.018>

Fox, J. (2022). *RcmdrMisc: R Commander Miscellaneous Functions*. 
R package version 2.7-2. <https://CRAN.R-project.org/package=RcmdrMisc>

Fox, John and Sanford Weisberg (2019). *An {R} Companion to Applied Regression* 
(**car**), Third Edition. Thousand Oaks CA: Sage. URL:
<https://socialsciences.mcmaster.ca/jfox/Books/Companion/>

Garrett, R.G. (2018). *rgr: Applied Geochemistry EDA*. R package version 1.1.15.
<https://CRAN.R-project.org/package=rgr>

Grunsky, E. C. (2010). The interpretation of geochemical survey data.
*Geochemistry: Exploration, Environment, Analysis*, **10**, 27-74.
<https://doi.org/10.1144/1467-7873/09-210>

Kassambara, A. and Mundt, F. (2020). 
*factoextra: Extract and Visualize the Results of Multivariate Data Analyses*. 
R package version 1.0.7. <https://CRAN.R-project.org/package=factoextra>

Maechler, M., Rousseeuw, P., Struyf, A., Hubert, M., Hornik, K.(2021). 
*cluster: Cluster Analysis Basics and Extensions*. R package version 2.1.2.
<https://CRAN.R-project.org/package=cluster>

Reimann, C., Filzmoser, P., Garrett, R. G., and Dutter, R. (2008). 
*Statistical Data Analysis Explained: Applied Environmental Statistics with R*
(First ed.). John Wiley & Sons, Chichester, UK.

Venables, W. N. and Ripley, B. D. (2002) *Modern Applied Statistics with S* 
(**MASS**). Fourth Edition. Springer, New York. ISBN 0-387-95457-0.
<http://www.stats.ox.ac.uk/pub/MASS4/>

Weihs, C., Ligges, U., Luebke, K. and Raabe, N. (2005). **klaR** -- Analyzing 
German Business Cycles. **In** Baier, D., Decker, R. and Schmidt-Thieme, L. 
(eds.). *Data Analysis and Decision Support*, 335-343, Springer-Verlag, Berlin.

Wickham, H. (2019). 
*stringr: Simple, Consistent Wrappers for Common String Operations*. 
R package version 1.4.0. <https://CRAN.R-project.org/package=stringr>

Xu, N., Rate, A. W., & Morgan, B. (2018). From source to sink: Rare-earth 
elements trace the legacy of sulfuric dredge spoils on estuarine sediments. 
*Science of The Total Environment*, **637-638**, 1537-1549.
<https://doi.org/10.1016/j.scitotenv.2018.04.398>
